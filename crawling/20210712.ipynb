{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ebd4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968889b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 네이버 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 네이버 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "#query_txt = '해양자원,도시재생'\n",
    "print(\"\\n\")\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'http://www.naver.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element_by_id(\"query\")\n",
    "driver.find_element_by_id(\"query\").click( ) #ID 값으로 찾음\n",
    "\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\") #enter 키를 의미한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b952bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 다음 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): 서진수 빅데이터\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 다음 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "#query_txt = '해양자원,도시재생'\n",
    "print(\"\\n\")\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'https://www.daum.net/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element_by_id(\"q\")\n",
    "driver.find_element_by_id(\"q\").click( ) #ID 값으로 찾음\n",
    "\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\") #enter 키를 의미한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af73bbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 구글 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): 서진수 빅데이터\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 구글 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "#query_txt = '해양자원,도시재생'\n",
    "print(\"\\n\")\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'https://www.google.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input\")\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input\").click( ) #ID 값으로 찾음\n",
    "\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\") #enter 키를 의미한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f4f1c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 경남대학교 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): 장학금\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 경남대학교 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "#query_txt = '해양자원,도시재생'\n",
    "print(\"\\n\")\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'https://www.kyungnam.ac.kr/sites/ko/index.do;jsessionid=F9555C4EED1B06F091EBC26B6ACA2A7C.worker2'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div/div[3]/ul/li[1]/a\").click()\n",
    "element = driver.find_element_by_id(\"top-search\")\n",
    "driver.find_element_by_id(\"top-search\").click( ) \n",
    "\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\") #enter 키를 의미한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2cf749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 네이버 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): 서진수 빅데이터\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  베타뉴스2018.04.11. 빅데이터 전문가 서진수, '강사양성' 직접 나선다   해당 과정에 대한 내용은 오프라인 설명회에서 공개되며, 참가를 원하는 사람은 19일까지 온오프믹스 홈페이지(KBS 명견만리 서진수 직강 '빅데이터 전문강사 되기' 무료 세미나)를 통해 신청하면 된다. 서진수 대표에...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  중도일보2018.04.10. 빅데이터 전문가 서진수, 4차 산업혁명 시대의 가치와 준비 방법 제시   지난 6일, 성수동 카페에서 진행된 명사와의 인터뷰에서 빅데이터 전문가 서진수 대표가 4차산업혁명과 빅데이터, 미래에 대해 약 4시간 동안 다양한 이야기를 나눴다. Q. 간단하게 본인 소개 부탁 드립니다. A. 저는 고향이...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  게임포커스2015.08.10. '빅데이터 분석 전도사' 서진수 소장 \"데이터 분석, 누구나 할 수 있다\"   게임포커스는 '빅데이터 분석 전도사'로 잘 알려진 서진수 데이터컨시어지랩 연구소장을 만나 빅데이터, 빅데이터 전문가란 어떤 것인지, 그가 강연 등에서 소개한 데이터 분석 툴 'R'은 어떤 것인지 들어봤다....\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  연합뉴스2015.05.20.네이버뉴스 '빅데이터 분석 전도사' 서진수, 무료 강연 진행   ▲도서출판더알음(대표 서진수)은 빅데이터 활용과 관련해 대학교와 대학원, 회사 등에서 무료 지식특강을 진행한다고 20일 밝혔다. 입문자와 초보자를 위한 빅데이터 분석 방법을 다루는 이번 강의는 취업난을 겪고...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  SBS CNBC2015.05.18.네이버뉴스 빅데이터 전문가 서진수 청년들의 희망 멘토로 강단 서다   저자 서진수는 \"빅데이터는 앞으로 산업 분야를 가리지 않고 우리가 사는 미래를 예측할 수 있는 도구가 될 것\"이라고 예상하면서 \"데이터 분석에 입문하고자 하는 분들이나 현직에서 데이터 관련 업무를 하고 있지만...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  뉴시스2015.05.04.네이버뉴스 ‘빅데이터 분석 전도사’ 서진수 주목, 인문대생 멘토   = 데이터 관리와 분석 전문가인 서진수가 빅데이터 활용 무료강연을 펼치고 있다. 그는 데이터 관련 분야에서 15년 정도 종사하면서 다양한 기업체의 데이터베이스를 구축하고 운영, 분석해왔다. 오라클 SQL과 PL/SQL...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  서울신문5면 TOP2018.10.19.네이버뉴스 [2018 서울미래컨퍼런스] “40만개 기사 1시간 만에 크롤링… 2020년 빅데이터...   [서울신문] 2015~2018년 언론 기사 크롤링 시연 연령별·성별 관심 뉴스 한번에 보여줘 “남북관계에서도 빅데이터 활용 가능”서진수 데이터앤피플 대표4개로 분할된 커다란 화면에 작은 글씨로 된 수백개의 기사...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  뉴스12016.05.10.네이버뉴스 인공지능 시대 개막, 빅데이터 분석 세미나 ‘화제’   ㈜데이터앤피플, ㈜컨시어지소프트의 서진수 대표는 빅데이터와 머신 러닝 관련 분야 전문가로 15년의 경력을 자랑하는 베테랑이다. 서진수 대표는 지식은 널리 퍼질수록 더 가치가 있고 세상을 밝게 할 수 있다는...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  데일리한국2016.05.02. 알파고 통해 바라본 미래…빅데이터 중요성 확대   빅데이터 전문가 서진수 대표 “빅데이터와 프로그래밍 관련지식이 곧 경쟁력” 세계를 휩쓴 올 상반기 최대의 이슈 가운데 하나는 알파고와 이세돌9단의 대국이었다. 인간과 인공지능의 대결로도 풀이되는 이번 대국은...\n",
      "\n",
      "\n",
      "문서 저장하기  Keep에 저장 Keep 바로가기  디지털타임스2016.04.28.네이버뉴스 인공지능 시대, 빅데이터와 프로그래밍 중요성 강조   ㈜데이터앤피플과 ㈜컨시어지소프트를 운영하는 빅데이터 전문가 서진수 대표에게 이야기를 들어보았다. 최근 KBS와 TV조선 등의 프로그램에서 빅데이터 분석 기술을 활용해 사회적 이슈를 분석하며 시청자들이...\n",
      "\n",
      "\n",
      "결과를 저장할 파일명을 쓰세요(예: c:\\temp\\riss.txt): naver.txt\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n",
      "수집된 결과는 naver.txt 에 저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "#네이버에서 뉴스 뽑기 메모장 저장\n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 네이버 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "#query_txt = '해양자원,도시재생'\n",
    "print(\"\\n\")\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "url = 'http://www.naver.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element_by_id(\"query\")\n",
    "driver.find_element_by_id(\"query\").click( ) #ID 값으로 찾음\n",
    "\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\") #enter 키를 의미한다\n",
    "\n",
    "driver.find_element_by_link_text('뉴스').click()\n",
    "#하이퍼 링크 연결, link_text (글자를 누를때): 페이지 변경에 많이 사용\n",
    "time.sleep(2)\n",
    "\n",
    "#Step 6.Beautiful Soup 로 본문 내용만 추출하기\n",
    "from bs4 import BeautifulSoup\n",
    "html_1 = driver.page_source #현재 페이지의 전체 소스코드를 다 가져오기\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('div','group_news').find_all('li')\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\" \").strip())\n",
    "    print(\"\\n\")\n",
    "\n",
    "#Step 7. 표준 출력 방향을 바꾸어 txt 파일에 저장하기\n",
    "import sys \n",
    "f_name = input('결과를 저장할 파일명을 쓰세요(예: c:\\\\temp\\\\riss.txt): ')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'a' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "file.close()    \n",
    "sys.stdout = orig_stdout  #원래대로 변경 - 다시 화면에 출력시켜라    \n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n",
    "print('수집된 결과는 %s 에 저장되었습니다' %f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "725988b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): 여름여행\n",
      "\n",
      "\n",
      "1여름여행\n",
      "\n",
      "\n",
      "2경기도\n",
      "\n",
      "\n",
      "3통영\n",
      "\n",
      "\n",
      "4강원도\n",
      "\n",
      "\n",
      "5가을여행\n",
      "\n",
      "\n",
      "6부산\n",
      "\n",
      "\n",
      "7제주도\n",
      "\n",
      "\n",
      "8계곡\n",
      "\n",
      "\n",
      "9여수\n",
      "\n",
      "\n",
      "10경주\n",
      "\n",
      "\n",
      "결과를 저장할 파일명을 쓰세요(예: c:\\temp\\riss.txt): 여름여행.txt\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n",
      "수집된 결과는 여름여행.txt 에 저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "print(\"\\n\")\n",
    "\n",
    "#Step 3. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "url = 'https://korean.visitkorea.or.kr'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#Step 4. 자동으로 검색어 입력 후 조회하기\n",
    "driver.find_element_by_id('openSearchFormInput').click( )\n",
    "element = driver.find_element_by_id('searchInput')\n",
    "driver.find_element_by_id('searchInput').click( )\n",
    "\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(2)\n",
    "\n",
    "html_1 = driver.page_source #현재 페이지의 전체 소스코드를 다 가져오기\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('div','area_sWordList').find_all('li')\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\" \").strip())\n",
    "    print(\"\\n\")\n",
    "\n",
    "#Step 7. 표준 출력 방향을 바꾸어 txt 파일에 저장하기\n",
    "import sys \n",
    "f_name = input('결과를 저장할 파일명을 쓰세요(예: c:\\\\temp\\\\riss.txt): ')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "file = open(f_name , 'a' , encoding='UTF-8')\n",
    "sys.stdout = file  #모니터에 출력하지 말고 file 에 출력해라\n",
    "\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "file.close()    \n",
    "sys.stdout = orig_stdout  #원래대로 변경 - 다시 화면에 출력시켜라    \n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n",
    "print('수집된 결과는 %s 에 저장되었습니다' %f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b08cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.maximize_window() 창을 최대화 시킴\n",
    "\n",
    "#숫자 제외한 글자만 뽑고 싶을때, em 사용\n",
    "# i.find('em'),get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a959dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 RISS 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): 해양자원\n",
      "\n",
      "\n",
      "위 키워드로 아래의 장르 중 어떤 장르의 정보를 수집할까요?: 2\n",
      " 위 장르 중 수집할 장르의 번호를 입력하세요: 2.\n",
      "3.결과를 저장할 csv형식의 파일명을 쓰세요(예: c:\\temp\\riss.csv): riss.csv\n",
      "4.결과를 저장할 xls형식의 파일명을 쓰세요(예: c:\\temp\\riss.xls): riss.xls\n",
      "검색하신 키워드 해양자원 (으)로 총 3,585 건의 학위논문이 검색되었습니다\n",
      "이 중에서 몇 건을 수집하시겠습니까?: 30\n",
      "30 건의 데이터를 수집하기 위해 3 페이지의 게시물을 조회합니다.\n",
      "1.번호: 1\n",
      "2.논문제목: 발표논문 / 해양생물자원으로서 해조류 : 생물활성물질의 정제와 분자적 응용\n",
      "3.저자: 홍용기(Yong Ki Hong)\n",
      "4.소속기관: 한국조류학회\n",
      "5.발표년도: 2000\n",
      "6.논문집: 국제심포지움 일정 및 발표논문집 - 21세기, 해양환경과 해양생물자원의 전망\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=508c47ca1906d5ecffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 2\n",
      "2.논문제목: 수거된 해양폐기물 자원화 기술 개발(Ⅰ)\n",
      "3.저자: 길상인(Sang-In Keel), 윤진한(Jin-Han Yun), 최연석(Yeon-Seok Choi), 강창구(Chang-Gu Kang), 유정석(Jeong-Seok Yu)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2002\n",
      "6.논문집: 한국해양환경·에너지학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=09ec1e3541fcc118ffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 3\n",
      "2.논문제목: 해양경찰 미래 발전을 위한 인적 자원 확보 방안연구\n",
      "3.저자: 윤병두\n",
      "4.소속기관: 한국해양경찰학회\n",
      "5.발표년도: 2021\n",
      "6.논문집: 한국해양경찰학회보\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=fcc6dea7df1a2c0fd18150b21a227875\n",
      "\n",
      "\n",
      "1.번호: 4\n",
      "2.논문제목: 침적 해양폐기물 수거사업과 자원 및 해양환경 조사사업의 연계방안에 대한 고찰\n",
      "3.저자: 김정협(Jeong-Hyop Kim), 장철호(Cheol-Ho Jang), 김광태(Gwang Tae Kim)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2012\n",
      "6.논문집: 한국해양환경·에너지학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e4815b407908f0abffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 5\n",
      "2.논문제목: 해양관광 활성화를 위한 해양문화관광자원 활용 방안 해양문화축제를 중심으로\n",
      "3.저자: 하경희(Ha, Kyoung-Hee)\n",
      "4.소속기관: 한국해양관광학회\n",
      "5.발표년도: 2018\n",
      "6.논문집: 해양관광학연구\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=d089e54bebbc73596aae8a972f9116fb\n",
      "\n",
      "\n",
      "1.번호: 6\n",
      "2.논문제목: 동아시아태평양 주요국가의 해양관리시스템 분석 : 해양질서관리와 해양자원관리를 중심으로\n",
      "3.저자: 주종광\n",
      "4.소속기관: 한국해양경찰학회\n",
      "5.발표년도: 2017\n",
      "6.논문집: 한국해양경찰학회 학술대회\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=437e1724024ae34f4884a65323211ff0\n",
      "\n",
      "\n",
      "1.번호: 7\n",
      "2.논문제목: 침적 해양폐기물 수거사업과 자원 및 해양환경 조사사업의 연계방안에 대한 고찰\n",
      "3.저자: 김정협,장철호,김광태,Kim,,Jeong-Hyop,Jang,,Cheol-Ho,Kim,,Gwang-Tae\n",
      "4.소속기관: 한국해양환경•에너지학회\n",
      "5.발표년도: 2012\n",
      "6.논문집: 한국해양환경공학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=32c6e6fc9ac7960a7ecd42904f0c5d65\n",
      "\n",
      "\n",
      "1.번호: 8\n",
      "2.논문제목: 해양·수산 분야의 자원봉사 활성화를 위한 연구 - 대학생 자원봉사의 정책적 시사점을 중심으로 -\n",
      "3.저자: 정우리,김향은,김세원,Jeong,,Woo-Lee,Kim,,Hyang-Eun,Kim,,Se-Won\n",
      "4.소속기관: The Korean Society of Marine Environment and safet\n",
      "5.발표년도: 2016\n",
      "6.논문집: 海洋環境安全學會誌\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=9d902b795f2b894eb7998d826d417196\n",
      "\n",
      "\n",
      "1.번호: 9\n",
      "2.논문제목: 해양심층수 자원ㆍ환경 관리시스템의 구축방향\n",
      "3.저자: 김현주(H.J. Kim), 정동호(D.H. Jung), 문덕수(D.S. Moon), 이문진(M.J. Lee)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2006\n",
      "6.논문집: 한국해양환경공학회 학술대회논문집\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=ccb4617c058b2945ffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 10\n",
      "2.논문제목: 발표논문 / 한국 연근해 해양환경의 현재와 미래\n",
      "3.저자: 김학균(Hak Gyoon Kim)\n",
      "4.소속기관: 한국조류학회\n",
      "5.발표년도: 2000\n",
      "6.논문집: 국제심포지움 일정 및 발표논문집 - 21세기, 해양환경과 해양생물자원의 전망\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=36ad9c8e8f6de724ffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 11\n",
      "2.논문제목: 발표논문 / 해양생물자원으로서 해조류 : 생물활성물질의 정제와 분자적 응용\n",
      "3.저자: 홍용기(Yong Ki Hong)\n",
      "4.소속기관: 한국조류학회\n",
      "5.발표년도: 2000\n",
      "6.논문집: 국제심포지움 일정 및 발표논문집 - 21세기, 해양환경과 해양생물자원의 전망\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=508c47ca1906d5ecffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 12\n",
      "2.논문제목: 수거된 해양폐기물 자원화 기술 개발(Ⅰ)\n",
      "3.저자: 길상인(Sang-In Keel), 윤진한(Jin-Han Yun), 최연석(Yeon-Seok Choi), 강창구(Chang-Gu Kang), 유정석(Jeong-Seok Yu)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2002\n",
      "6.논문집: 한국해양환경·에너지학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=09ec1e3541fcc118ffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 13\n",
      "2.논문제목: 해양경찰 미래 발전을 위한 인적 자원 확보 방안연구\n",
      "3.저자: 윤병두\n",
      "4.소속기관: 한국해양경찰학회\n",
      "5.발표년도: 2021\n",
      "6.논문집: 한국해양경찰학회보\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=fcc6dea7df1a2c0fd18150b21a227875\n",
      "\n",
      "\n",
      "1.번호: 14\n",
      "2.논문제목: 침적 해양폐기물 수거사업과 자원 및 해양환경 조사사업의 연계방안에 대한 고찰\n",
      "3.저자: 김정협(Jeong-Hyop Kim), 장철호(Cheol-Ho Jang), 김광태(Gwang Tae Kim)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2012\n",
      "6.논문집: 한국해양환경·에너지학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=e4815b407908f0abffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 15\n",
      "2.논문제목: 해양관광 활성화를 위한 해양문화관광자원 활용 방안 해양문화축제를 중심으로\n",
      "3.저자: 하경희(Ha, Kyoung-Hee)\n",
      "4.소속기관: 한국해양관광학회\n",
      "5.발표년도: 2018\n",
      "6.논문집: 해양관광학연구\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=d089e54bebbc73596aae8a972f9116fb\n",
      "\n",
      "\n",
      "1.번호: 16\n",
      "2.논문제목: 동아시아태평양 주요국가의 해양관리시스템 분석 : 해양질서관리와 해양자원관리를 중심으로\n",
      "3.저자: 주종광\n",
      "4.소속기관: 한국해양경찰학회\n",
      "5.발표년도: 2017\n",
      "6.논문집: 한국해양경찰학회 학술대회\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=437e1724024ae34f4884a65323211ff0\n",
      "\n",
      "\n",
      "1.번호: 17\n",
      "2.논문제목: 침적 해양폐기물 수거사업과 자원 및 해양환경 조사사업의 연계방안에 대한 고찰\n",
      "3.저자: 김정협,장철호,김광태,Kim,,Jeong-Hyop,Jang,,Cheol-Ho,Kim,,Gwang-Tae\n",
      "4.소속기관: 한국해양환경•에너지학회\n",
      "5.발표년도: 2012\n",
      "6.논문집: 한국해양환경공학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=32c6e6fc9ac7960a7ecd42904f0c5d65\n",
      "\n",
      "\n",
      "1.번호: 18\n",
      "2.논문제목: 해양·수산 분야의 자원봉사 활성화를 위한 연구 - 대학생 자원봉사의 정책적 시사점을 중심으로 -\n",
      "3.저자: 정우리,김향은,김세원,Jeong,,Woo-Lee,Kim,,Hyang-Eun,Kim,,Se-Won\n",
      "4.소속기관: The Korean Society of Marine Environment and safet\n",
      "5.발표년도: 2016\n",
      "6.논문집: 海洋環境安全學會誌\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=9d902b795f2b894eb7998d826d417196\n",
      "\n",
      "\n",
      "1.번호: 19\n",
      "2.논문제목: 해양심층수 자원ㆍ환경 관리시스템의 구축방향\n",
      "3.저자: 김현주(H.J. Kim), 정동호(D.H. Jung), 문덕수(D.S. Moon), 이문진(M.J. Lee)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2006\n",
      "6.논문집: 한국해양환경공학회 학술대회논문집\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=ccb4617c058b2945ffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 20\n",
      "2.논문제목: 발표논문 / 한국 연근해 해양환경의 현재와 미래\n",
      "3.저자: 김학균(Hak Gyoon Kim)\n",
      "4.소속기관: 한국조류학회\n",
      "5.발표년도: 2000\n",
      "6.논문집: 국제심포지움 일정 및 발표논문집 - 21세기, 해양환경과 해양생물자원의 전망\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=36ad9c8e8f6de724ffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 21\n",
      "2.논문제목: 해양심층수 에너지자원 이용 타당성 분석 연구\n",
      "3.저자: 김정협(Jeong-Hyop Kim), 김광태(Gwang Tae Kim), 박세헌(Se-Hun Park), 오위영(Wee-Yeong Oh), 김현주(Hyeon-Ju Kim)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2012\n",
      "6.논문집: 한국해양환경·에너지학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=553d20d668277201ffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 22\n",
      "2.논문제목: 우리나라 海洋生態資源의 現況 및 價値\n",
      "3.저자: 李興東\n",
      "4.소속기관: 韓國海洋水産開發院\n",
      "5.발표년도: 2000\n",
      "6.논문집: (월간) 해양수산\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=2cc330dffeaba081ffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 23\n",
      "2.논문제목: 우리나라 관할해역 내 해양자원 관리현황 및 정책 개선방향\n",
      "3.저자: 박수진(Su Jin Park)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2014\n",
      "6.논문집: 한국해양환경공학회 학술대회논문집\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=282dfd2189931dee6aae8a972f9116fb\n",
      "\n",
      "\n",
      "1.번호: 24\n",
      "2.논문제목: 북극 석유자원개발과 해양플랜트 산업의 현황 및 전망\n",
      "3.저자: 신효진,문영준,임종세\n",
      "4.소속기관: 한국자원공학회\n",
      "5.발표년도: 2018\n",
      "6.논문집: 한국자원공학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=fa23a2c7026d79dbe9810257f7042666\n",
      "\n",
      "\n",
      "1.번호: 25\n",
      "2.논문제목: 우리나라 海洋生態資源의 現況 및 價値\n",
      "3.저자: 李興東\n",
      "4.소속기관: 韓國海洋水産開發院\n",
      "5.발표년도: 1998\n",
      "6.논문집: (월간) 해양수산\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=6fe5d26d9f55737affe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 26\n",
      "2.논문제목: 수산자원 보호를 위한 바다낚시 규제의 필요성과 해양경찰의 역할 모색\n",
      "3.저자: 이기수\n",
      "4.소속기관: 한국해양경찰학회\n",
      "5.발표년도: 2020\n",
      "6.논문집: 한국해양경찰학회보\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=7ba62b1b685a43d9c85d2949c297615a\n",
      "\n",
      "\n",
      "1.번호: 27\n",
      "2.논문제목: 해양자원의 웰니스 산업적 이용가능성과 해외치유관광 개발 전략\n",
      "3.저자: 채동렬(Chae Dong Ryul)\n",
      "4.소속기관: 한국해양관광학회\n",
      "5.발표년도: 2017\n",
      "6.논문집: 해양관광학연구\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=ee2270811362e5057f7a54760bb41745\n",
      "\n",
      "\n",
      "1.번호: 28\n",
      "2.논문제목: 해양심층수와 지하염수 자원의 특성\n",
      "3.저자: 문덕수(D.S. Moon), 정동호(D.H. Jung), 김현주(H.J. Kim), 신필권(P.K. Shin)\n",
      "4.소속기관: 한국해양환경·에너지학회\n",
      "5.발표년도: 2004\n",
      "6.논문집: 한국해양환경·에너지학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=15d0e8054b146f6bffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "1.번호: 29\n",
      "2.논문제목: 해양심층수 에너지자원 이용 타당성 분석 연구\n",
      "3.저자: 김정협,김광태,박세헌,오위영,김현주,Kim,,Jeong-Hyop,Kim,,Gwang-Tae,Park,,Se-Hun,Oh,,Wee-Yeong,Kim,,Hyeon-Ju\n",
      "4.소속기관: 한국해양환경•에너지학회\n",
      "5.발표년도: 2012\n",
      "6.논문집: 한국해양환경공학회지\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=4d7bd387e75b4833b7998d826d417196\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.번호: 30\n",
      "2.논문제목: 海洋에너지資源 開發硏究의 現狀과 展望\n",
      "3.저자: 安熙道\n",
      "4.소속기관: 한국해양수산개발원\n",
      "5.발표년도: 1989\n",
      "6.논문집: 해양정책연구\n",
      "7. url: /search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&control_no=258ea3672c4812cdffe0bdc3ef48d419\n",
      "\n",
      "\n",
      "요청하신 작업이 모두 완료되었습니다\n",
      "요청하신 데이터 수집 작업이 정상적으로 완료되었습니다\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-5a4619d6e116>:165: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  df.to_excel(fx_name,index=False, encoding=\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "# riss.kr 에서 특정 키워드로 논문 / 학술 자료 검색하기\n",
    "\n",
    "#Step 1. 필요한 모듈을 로딩합니다\n",
    "from selenium import webdriver\n",
    "import time \n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 RISS 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "print(\"\\n\")\n",
    "\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "url = 'http://www.riss.kr/'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#Step 5. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element_by_id(\"query\")\n",
    "driver.find_element_by_id(\"query\").click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(2)\n",
    "\n",
    "opt = int(input('위 키워드로 아래의 장르 중 어떤 장르의 정보를 수집할까요?: '))\n",
    "if opt == 1:\n",
    "    driver.find_element_by_link_text('학위논문').click()\n",
    "if opt == 2:\n",
    "    driver.find_element_by_link_text('국내학술논문').click()\n",
    "if opt == 3:\n",
    "    driver.find_element_by_link_text('해외학술논문').click()\n",
    "if opt == 4:\n",
    "    driver.find_element_by_link_text('학술지').click()\n",
    "if opt == 5:\n",
    "    driver.find_element_by_link_text('단행본').click()\n",
    "if opt == 6:\n",
    "    driver.find_element_by_link_text('공개강의').click()\n",
    "if opt == 7:\n",
    "    driver.find_element_by_link_text('연구보고서').click()\n",
    "\n",
    "print(\" 위 장르 중 수집할 장르의 번호를 입력하세요: %d.\" %opt)\n",
    "\n",
    "\n",
    "fc_name = input('3.결과를 저장할 csv형식의 파일명을 쓰세요(예: c:\\\\temp\\\\riss.csv): ')\n",
    "fx_name = input('4.결과를 저장할 xls형식의 파일명을 쓰세요(예: c:\\\\temp\\\\riss.xls): ')\n",
    "\n",
    "#Step 7.Beautiful Soup 로 본문 내용만 추출하기\n",
    "from bs4 import BeautifulSoup\n",
    "html_1 = driver.page_source\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('div','srchResultListW').find_all('li')\n",
    "#for i in content_1 :\n",
    "    #print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "    #Step 8. 총 검색 건수를 보여주고 수집할 건수 입력받기\n",
    "import math\n",
    "total_cnt = soup_1.find('div','searchBox').find('span','num').get_text()\n",
    "print('검색하신 키워드 %s (으)로 총 %s 건의 학위논문이 검색되었습니다' %(query_txt,total_cnt))\n",
    "collect_cnt = int(input('이 중에서 몇 건을 수집하시겠습니까?: '))\n",
    "collect_page_cnt = math.ceil(collect_cnt / 10)\n",
    "print('%s 건의 데이터를 수집하기 위해 %s 페이지의 게시물을 조회합니다.' %(collect_cnt,collect_page_cnt))\n",
    "\n",
    "#Step 9. 각 항목별로 데이터를 추출하여 리스트에 저장하기\n",
    "no2 = [ ]        #번호 저장\n",
    "title2 = [ ]     #논문제목 저장\n",
    "writer2 = [ ]    #논문저자 저장\n",
    "org2 = [ ]       #소속기관 저장\n",
    "year2 = []\n",
    "ref2 = []\n",
    "url2 = []\n",
    "no = 1\n",
    "\n",
    "# 다음 페이지 번호 만들기\n",
    "page_no=[ ]\n",
    "\n",
    "for i in range(10,collect_cnt) :\n",
    "    if i % 10 == 0 :\n",
    "            page_no.append(i + 1)\n",
    "\n",
    "for a in range(1, collect_page_cnt + 1) :\n",
    "    \n",
    "    html_2 = driver.page_source\n",
    "    soup_2 = BeautifulSoup(html_2, 'html.parser')\n",
    "\n",
    "    content_2 = soup_2.find('div','srchResultListW').find_all('li')\n",
    "    \n",
    "    for b in content_2 :    \n",
    "        #1. 논문제목 있을 경우만\n",
    "        try :\n",
    "            title = b.find('div','cont').find('p','title').get_text()\n",
    "        except :\n",
    "            continue\n",
    "        else :\n",
    "            f = open(fc_name, 'a' , encoding=\"UTF-8\")\n",
    "            print('1.번호:',no)\n",
    "            no2.append(no)\n",
    "            f.write('\\n'+'1.번호:' + str(no))\n",
    "\n",
    "            print('2.논문제목:',title)\n",
    "            title2.append(title)\n",
    "            f.write('\\n' + '2.논문제목:' + title)\n",
    "            \n",
    "            writer = b.find('span','writer').get_text()\n",
    "            print('3.저자:',writer)\n",
    "            writer2.append(writer)\n",
    "            f.write('\\n' + '3.저자:' + writer)\n",
    "\n",
    "            org = b.find('span','assigned').get_text()\n",
    "            print('4.소속기관:' , org)\n",
    "            org2.append(org)\n",
    "            f.write('\\n' + '4.소속기관:' + org)\n",
    "            \n",
    "            year = b.find('p','etc').find_all('span')\n",
    "            year = year[2].get_text()\n",
    "            print('5.발표년도:' , year)\n",
    "            year2.append(year)\n",
    "            f.write('\\n' + '5.발표년도:' + year)            \n",
    "            \n",
    "            ref = b.find('p','etc').find_all('span')\n",
    "            ref = ref[3].get_text()\n",
    "            print('6.논문집:',ref)\n",
    "            ref2.append(ref)\n",
    "            f.write('\\n' + '6.논문집:' + ref)\n",
    "            \n",
    "            url = b.find('p','title').a['href']\n",
    "            print('7. url:' , url)\n",
    "            url2.append(url)\n",
    "            f.write('\\n' + '7. url:' + url + '\\n')\n",
    "            \n",
    "            f.close( )\n",
    "            \n",
    "            no += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            if no > collect_cnt :\n",
    "                break\n",
    "\n",
    "            time.sleep(1)        # 페이지 변경 전 1초 대기 \n",
    "\n",
    "        try:\n",
    "            driver.find_element_by_link_text('%s' %a).click()\n",
    "            \n",
    "        except:\n",
    "             driver.find_element_by_link_text('다음 페이지로').click()# 다음 페이지번호 클릭\n",
    "            \n",
    "print(\"요청하신 작업이 모두 완료되었습니다\")\n",
    "\n",
    "# Step 10. 수집된 데이터를 xls와 csv 형태로 저장하기\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['번호']=no2\n",
    "df['제목']=pd.Series(title2)\n",
    "df['저자']=pd.Series(writer2)\n",
    "df['소속(발행)기관']=pd.Series(org2)\n",
    "df['발표년도']=pd.Series(year2)\n",
    "df['논문집']=pd.Series(ref2)\n",
    "df['url']=pd.Series(url2)\n",
    "\n",
    "# xls 형태로 저장하기\n",
    "df.to_excel(fx_name,index=False, encoding=\"utf-8\")\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "df.to_csv(fc_name,index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd2b7f",
   "metadata": {},
   "source": [
    "find('a')['href']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
